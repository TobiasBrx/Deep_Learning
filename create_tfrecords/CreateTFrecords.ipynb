{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from google.cloud import storage\n",
    "import io\n",
    "import nibabel as nib\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import gcsfs\n",
    "import random\n",
    "import re\n",
    "from nilearn import image\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rel_path = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first create this file via IAM management on Google Cloud Platform\n",
    "#change path\n",
    "api_key = \"deep-learning-255016-4350337ed6f4.json\"\n",
    "credentials = service_account.Credentials.from_service_account_file(api_key)\n",
    "client = storage.Client(credentials=credentials, project=\"deep-learning\")\n",
    "\n",
    "fs = gcsfs.GCSFileSystem(token=api_key, project=\"deep-learning\")\n",
    "with fs.open('mri_data_bucket/ADNI_t1_list_with_fsstatus_20190111.csv') as f:\n",
    "    df = pd.read_csv(f)\n",
    "df.to_csv('labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"mri_data_bucket\"\n",
    "bucket = client.get_bucket(bucket_name)\n",
    "prefix = \"data\"\n",
    "blobs = bucket.list_blobs(prefix=prefix)\n",
    "\n",
    "file_names = [blob.name for blob in blobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=df[['Subject','T1.SERIESID','Group']].copy()\n",
    "\n",
    "def labels_slice(labels, groups):\n",
    "    \n",
    "    filter_ = pd.Series(np.repeat(0, labels.shape[0]), index=labels.index)\n",
    "    for group in groups:\n",
    "        group_filter = (labels.Group == group)\n",
    "        filter_ = filter_ | group_filter\n",
    "    labels = labels[pd.Series(filter_)]\n",
    "    return labels\n",
    "\n",
    "labels = labels_slice(labels, ['CN', 'AD', 'EMCI', 'LMCI', 'MCI'])\n",
    "\n",
    "\n",
    "\n",
    "labels['new_ind']=labels['Subject']+\"_\"+labels['T1.SERIESID'].astype(str)\n",
    "labels.loc[labels.Group == 'CN','Group']=0\n",
    "labels.loc[labels.Group == 'AD','Group']=1\n",
    "labels.loc[labels.Group == 'EMCI','Group']=2\n",
    "labels.loc[labels.Group == 'LMCI','Group']=3\n",
    "labels.loc[labels.Group == 'MCI','Group']=4\n",
    "labels = labels.set_index('new_ind')\n",
    "labels=labels.drop(columns=['Subject','T1.SERIESID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images:  10435\n",
      "Number of images without label:  787\n",
      "Labels:  9648\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of images: \", len(file_names))\n",
    "print(\"Number of images without label: \", len(file_names) - labels.shape[0])\n",
    "print(\"Labels: \", labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = re.compile(r'S\\d+')\n",
    "pattern2 = re.compile(r'\\d+_S_\\d+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(file_names, path='../data'):\n",
    "    \"\"\"\n",
    "    run only 1 time to transfer the data from the bucket to the path\n",
    "    transfers only data with label\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    count=0\n",
    "    with_label = []\n",
    "    for filename in file_names:\n",
    "        filename=filename[5:]\n",
    "        try:\n",
    "            series_id = re.search(pattern1, filename).group(0)[1:]\n",
    "            subject = re.search(pattern2,filename).group(0)\n",
    "            ind=subject+\"_\"+series_id\n",
    "        \n",
    "            label=labels.loc[ind,'Group']          \n",
    "            blob = bucket.blob('data/'+filename)\n",
    "            blob.download_to_filename(path + filename)\n",
    "            count+=1\n",
    "\n",
    "            if count % 500 ==0:\n",
    "                print(count)\n",
    "        except:\n",
    "            continue\n",
    "    print('Total files downloaded: ', count)\n",
    "#download(file_names, path=rel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pictures with labels but no features:  83\n"
     ]
    }
   ],
   "source": [
    "with_label = [i for i in file_names if (\n",
    "    re.search(pattern2, i[5:]).group(0)+\"_\"+re.search(pattern1, i[5:]).group(0)[1:] in labels.index)]\n",
    "\n",
    "ids = [re.search(pattern2, i[5:]).group(0)+\"_\"+re.search(pattern1, i[5:]).group(0)[1:] for i in file_names]\n",
    "\n",
    "label_with_no_image = [i for i in labels.index if i not in ids]\n",
    "print('Number of pictures with labels but no features: ', len(label_with_no_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pictures that have the same ID but different files:  84\n"
     ]
    }
   ],
   "source": [
    "buffer = []\n",
    "two_image_same_id = []\n",
    "count = 0\n",
    "for i in file_names:\n",
    "    ind = re.search(pattern2, i[5:]).group(0)+\"_\"+re.search(pattern1, i[5:]).group(0)[1:] \n",
    "    if (ind in labels.index) and (ind in buffer):\n",
    "        two_image_same_id.append(ind)\n",
    "        count +=1\n",
    "    buffer.append(ind)\n",
    "print('Pictures that have the same ID but different files: ', len(two_image_same_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of two files with same ID\n",
      "002_S_1261_101646 data/002_S_1261-S101646-T_T1_brain_mni305.nii\n",
      "002_S_1261_101646 data/002_S_1261_S101646_T1_brain_mni305.nii\n"
     ]
    }
   ],
   "source": [
    "# TWO IMAGES ONE LABEL. BOTH GET DOWNLOADED \n",
    "example = \"002_S_1261_101646\"\n",
    "print(\"Example of two files with same ID\")\n",
    "for i in file_names:\n",
    "    ind = re.search(pattern2, i[5:]).group(0)+\"_\"+re.search(pattern1, i[5:]).group(0)[1:] \n",
    "    if ind == example:\n",
    "        print(ind, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Located at:  ['/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Located at: \", get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_label = np.asarray([name[5:] for name in with_label])\n",
    "#with_label = with_label[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 86.195 seconds ---\n",
      "100\n",
      "--- 80.236 seconds ---\n",
      "200\n",
      "--- 79.895 seconds ---\n",
      "300\n",
      "--- 80.716 seconds ---\n",
      "400\n",
      "--- 79.880 seconds ---\n",
      "500\n",
      "--- 80.396 seconds ---\n",
      "600\n",
      "--- 80.641 seconds ---\n",
      "700\n",
      "--- 80.824 seconds ---\n",
      "800\n",
      "--- 79.659 seconds ---\n",
      "900\n",
      "--- 81.631 seconds ---\n",
      "1000\n",
      "--- 79.346 seconds ---\n",
      "1100\n",
      "--- 80.456 seconds ---\n",
      "1200\n",
      "--- 81.188 seconds ---\n",
      "1300\n",
      "--- 81.451 seconds ---\n",
      "1400\n",
      "--- 81.946 seconds ---\n",
      "1500\n",
      "--- 81.286 seconds ---\n",
      "1600\n",
      "--- 81.941 seconds ---\n",
      "1700\n",
      "--- 82.126 seconds ---\n",
      "1800\n",
      "--- 82.862 seconds ---\n",
      "1900\n",
      "--- 81.197 seconds ---\n",
      "2000\n",
      "--- 79.340 seconds ---\n",
      "2100\n",
      "--- 79.693 seconds ---\n",
      "2200\n",
      "--- 81.068 seconds ---\n",
      "2300\n",
      "--- 79.629 seconds ---\n",
      "2400\n",
      "--- 80.170 seconds ---\n",
      "2500\n",
      "--- 78.943 seconds ---\n",
      "2600\n",
      "--- 79.710 seconds ---\n",
      "2700\n",
      "--- 82.454 seconds ---\n",
      "2800\n",
      "--- 87.024 seconds ---\n",
      "2900\n",
      "--- 84.882 seconds ---\n",
      "3000\n",
      "--- 87.953 seconds ---\n",
      "3100\n",
      "--- 88.712 seconds ---\n",
      "3200\n",
      "--- 89.543 seconds ---\n",
      "3300\n",
      "--- 89.013 seconds ---\n",
      "3400\n",
      "--- 88.430 seconds ---\n",
      "3500\n",
      "--- 87.120 seconds ---\n",
      "3600\n",
      "--- 86.832 seconds ---\n",
      "3700\n",
      "--- 88.728 seconds ---\n",
      "3800\n",
      "--- 87.897 seconds ---\n",
      "3900\n",
      "--- 87.844 seconds ---\n",
      "4000\n",
      "--- 88.993 seconds ---\n",
      "4100\n",
      "--- 83.163 seconds ---\n",
      "4200\n",
      "--- 80.009 seconds ---\n",
      "4300\n",
      "--- 80.699 seconds ---\n",
      "4400\n",
      "--- 81.112 seconds ---\n",
      "4500\n",
      "--- 79.325 seconds ---\n",
      "4600\n",
      "--- 79.921 seconds ---\n",
      "4700\n",
      "--- 79.601 seconds ---\n",
      "4800\n",
      "--- 80.567 seconds ---\n",
      "4900\n",
      "--- 81.407 seconds ---\n",
      "5000\n",
      "--- 82.598 seconds ---\n",
      "5100\n",
      "--- 79.891 seconds ---\n",
      "5200\n",
      "--- 81.970 seconds ---\n",
      "5300\n",
      "--- 80.234 seconds ---\n",
      "5400\n",
      "--- 82.582 seconds ---\n",
      "5500\n",
      "--- 80.431 seconds ---\n",
      "5600\n",
      "--- 80.549 seconds ---\n",
      "5700\n",
      "--- 83.803 seconds ---\n",
      "5800\n",
      "--- 82.623 seconds ---\n",
      "5900\n",
      "--- 81.532 seconds ---\n",
      "6000\n",
      "--- 81.816 seconds ---\n",
      "6100\n",
      "--- 83.687 seconds ---\n",
      "6200\n",
      "--- 87.911 seconds ---\n",
      "6300\n",
      "--- 87.650 seconds ---\n",
      "6400\n",
      "--- 88.004 seconds ---\n",
      "6500\n",
      "--- 87.389 seconds ---\n",
      "6600\n",
      "--- 87.941 seconds ---\n",
      "6700\n",
      "--- 87.608 seconds ---\n",
      "6800\n",
      "--- 85.866 seconds ---\n",
      "6900\n",
      "--- 87.370 seconds ---\n",
      "7000\n",
      "--- 88.026 seconds ---\n",
      "7100\n",
      "--- 90.170 seconds ---\n",
      "7200\n",
      "--- 88.082 seconds ---\n",
      "7300\n",
      "--- 87.095 seconds ---\n",
      "7400\n",
      "--- 88.252 seconds ---\n",
      "7500\n",
      "--- 87.043 seconds ---\n",
      "7600\n",
      "--- 89.216 seconds ---\n",
      "7700\n",
      "--- 89.883 seconds ---\n",
      "7800\n",
      "--- 88.718 seconds ---\n",
      "7900\n",
      "--- 87.740 seconds ---\n",
      "8000\n",
      "--- 87.621 seconds ---\n",
      "8100\n",
      "--- 90.499 seconds ---\n",
      "8200\n",
      "--- 88.062 seconds ---\n",
      "8300\n",
      "--- 90.807 seconds ---\n",
      "8400\n",
      "--- 88.507 seconds ---\n",
      "8500\n",
      "--- 88.970 seconds ---\n",
      "8600\n",
      "--- 88.518 seconds ---\n",
      "8700\n",
      "--- 88.466 seconds ---\n",
      "8800\n",
      "--- 88.388 seconds ---\n",
      "8900\n",
      "--- 88.466 seconds ---\n",
      "9000\n",
      "--- 88.742 seconds ---\n",
      "9100\n",
      "--- 91.144 seconds ---\n",
      "9200\n",
      "--- 88.935 seconds ---\n",
      "9300\n",
      "--- 89.643 seconds ---\n",
      "9400\n",
      "--- 91.202 seconds ---\n",
      "9500\n",
      "--- 89.191 seconds ---\n",
      "9600\n"
     ]
    }
   ],
   "source": [
    "def normalise_GPU(file_names):\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    with strategy.scope():\n",
    "        min_x=tf.ones(256**3)*np.inf\n",
    "        max_x=tf.zeros(256**3)\n",
    "        for filename in file_names:\n",
    "\n",
    "            image_ = nib.load(rel_path + filename)\n",
    "            image = image_.get_data()\n",
    "            x = tf.reshape(image, [-1])\n",
    "            min_x = tf.minimum(min_x, x)           \n",
    "            max_x = tf.maximum(max_x, x)\n",
    "            count += 1\n",
    "            if count % 200 == 0:\n",
    "                print(\"--- {:.1f} seconds ---\".format(time.time() - start_time))\n",
    "                print(count)\n",
    "                start_time = time.time()\n",
    "    return min_x, max_x\n",
    "\n",
    "#min_, max_ = normalise_GPU(with_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 82.4 seconds ---\n",
      "200\n",
      "--- 81.6 seconds ---\n",
      "400\n",
      "--- 81.9 seconds ---\n",
      "600\n",
      "--- 79.5 seconds ---\n",
      "800\n",
      "--- 82.0 seconds ---\n",
      "1000\n",
      "--- 82.2 seconds ---\n",
      "1200\n",
      "--- 81.1 seconds ---\n",
      "1400\n",
      "--- 83.6 seconds ---\n",
      "1600\n",
      "--- 79.4 seconds ---\n",
      "1800\n",
      "--- 79.5 seconds ---\n",
      "2000\n",
      "--- 79.7 seconds ---\n",
      "2200\n",
      "--- 82.7 seconds ---\n",
      "2400\n",
      "--- 82.1 seconds ---\n",
      "2600\n",
      "--- 83.1 seconds ---\n",
      "2800\n",
      "--- 82.9 seconds ---\n",
      "3000\n",
      "--- 81.3 seconds ---\n",
      "3200\n",
      "--- 82.6 seconds ---\n",
      "3400\n",
      "--- 81.9 seconds ---\n",
      "3600\n",
      "--- 80.1 seconds ---\n",
      "3800\n",
      "--- 83.9 seconds ---\n",
      "4000\n",
      "--- 80.8 seconds ---\n",
      "4200\n",
      "--- 84.4 seconds ---\n",
      "4400\n",
      "--- 82.5 seconds ---\n",
      "4600\n",
      "--- 83.6 seconds ---\n",
      "4800\n",
      "--- 83.0 seconds ---\n",
      "5000\n",
      "--- 82.6 seconds ---\n",
      "5200\n",
      "--- 81.6 seconds ---\n",
      "5400\n",
      "--- 82.2 seconds ---\n",
      "5600\n",
      "--- 83.4 seconds ---\n",
      "5800\n",
      "--- 83.3 seconds ---\n",
      "6000\n",
      "--- 84.2 seconds ---\n",
      "6200\n",
      "--- 83.3 seconds ---\n",
      "6400\n",
      "--- 84.5 seconds ---\n",
      "6600\n",
      "--- 81.1 seconds ---\n",
      "6800\n",
      "--- 80.7 seconds ---\n",
      "7000\n",
      "--- 81.9 seconds ---\n",
      "7200\n",
      "--- 83.0 seconds ---\n",
      "7400\n",
      "--- 81.6 seconds ---\n",
      "7600\n",
      "--- 82.9 seconds ---\n",
      "7800\n",
      "--- 82.1 seconds ---\n",
      "8000\n",
      "--- 84.2 seconds ---\n",
      "8200\n",
      "--- 83.9 seconds ---\n",
      "8400\n",
      "--- 83.2 seconds ---\n",
      "8600\n",
      "--- 82.2 seconds ---\n",
      "8800\n",
      "--- 84.5 seconds ---\n",
      "9000\n",
      "--- 85.0 seconds ---\n",
      "9200\n",
      "--- 84.2 seconds ---\n",
      "9400\n",
      "--- 85.7 seconds ---\n",
      "9600\n"
     ]
    }
   ],
   "source": [
    "def normalise_XYZ_GPU(file_names, x_=127, y_=127, z_=127):\n",
    "    count=0\n",
    "    start_time = time.time()\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    with strategy.scope():\n",
    "        min_x, min_y, min_z = tf.ones(156**2)*np.inf, tf.ones(156**2)*np.inf, tf.ones(156**2)*np.inf\n",
    "        max_x, max_y, max_z = tf.zeros(156**2), tf.zeros(156**2), tf.zeros(156**2)\n",
    "    \n",
    "        for filename in file_names:\n",
    "\n",
    "            image_ = nib.load(rel_path+filename)\n",
    "            image = image_.get_data()\n",
    "            x = image[x_,50:206,50:206]\n",
    "            x = tf.reshape(x, [-1])\n",
    "          \n",
    "            y = image[50:206,y_,50:206]\n",
    "            y = tf.reshape(y, [-1])\n",
    "          \n",
    "            z = image[50:206,50:206,z_]\n",
    "            z = tf.reshape(z, [-1])\n",
    "                     \n",
    "            min_x = tf.minimum(min_x, x)\n",
    "            min_y = tf.minimum(min_y, y)\n",
    "            min_z = tf.minimum(min_z, z)\n",
    "          \n",
    "            max_x = tf.maximum(max_x, x)\n",
    "            max_y = tf.maximum(max_y, y)\n",
    "            max_z = tf.maximum(max_z, z)\n",
    "            count+=1\n",
    "            if count % 200 == 0:\n",
    "                print(\"--- {:.1f} seconds ---\".format(time.time() - start_time))\n",
    "                print(count)\n",
    "                start_time = time.time()\n",
    "              \n",
    "        min_ = [min_x, min_y, min_z]\n",
    "        max_ = [max_x, max_y, max_z]\n",
    "        return min_, max_\n",
    "\n",
    "min_xyz, max_xyz = normalise_XYZ_GPU(with_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_CPU(file_names):\n",
    "    count=0\n",
    "    start_time = time.time()\n",
    "    min_x=np.ones(256**3)*np.inf\n",
    "    max_x=np.zeros(256**3)\n",
    "    for filename in file_names:\n",
    "\n",
    "        image_ = nib.load(rel_path + filename)\n",
    "        image = image_.get_data()\n",
    "        x=np.array(image.ravel())\n",
    "                   \n",
    "        min_x=np.minimum(min_x,x)           \n",
    "        max_x=np.maximum(max_x,x)\n",
    "\n",
    "        count+=1\n",
    "        if count % 200 ==0:\n",
    "            print(\"--- {:.1f} seconds ---\".format(time.time() - start_time))\n",
    "            print(count)\n",
    "            start_time = time.time()\n",
    "    return min_x, max_x\n",
    "\n",
    "#min_flat, max_flat = normalise_CPU(with_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16777216,) (16777216,)\n",
      "tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(16777216,), dtype=float32)\n",
      "tf.Tensor([20.757666 18.241428 22.012058 ...  0.        0.        0.      ], shape=(16777216,), dtype=float32)\n",
      "[<tf.Tensor: id=194008, shape=(24336,), dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>, <tf.Tensor: id=194009, shape=(24336,), dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>, <tf.Tensor: id=194010, shape=(24336,), dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>]\n",
      "[<tf.Tensor: id=194011, shape=(24336,), dtype=float32, numpy=\n",
      "array([110.553024, 112.68892 , 115.255714, ..., 110.00697 , 110.027626,\n",
      "       110.      ], dtype=float32)>, <tf.Tensor: id=194012, shape=(24336,), dtype=float32, numpy=\n",
      "array([110.      , 109.852325, 109.59591 , ...,  99.396126,  92.450714,\n",
      "        87.962585], dtype=float32)>, <tf.Tensor: id=194013, shape=(24336,), dtype=float32, numpy=\n",
      "array([ 78.40503 ,  74.64166 ,  68.488785, ..., 110.48177 , 115.33022 ,\n",
      "       103.07219 ], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(min_.shape, max_.shape)\n",
    "print(min_)\n",
    "print(max_)\n",
    "\n",
    "print(min_xyz)\n",
    "print(max_xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_min_max():\n",
    "    if not os.path.exists('Normalizing_files'):\n",
    "        os.makedirs('Normalizing_files')\n",
    "    np.save('Normalizing_files/min_flat_3d', min_)\n",
    "    np.save('Normalizing_files/max_flat_3d', max_)\n",
    "    \n",
    "#save_min_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_min_max_xyz():\n",
    "    if not os.path.exists('Normalizing_files'):\n",
    "        os.makedirs('Normalizing_files')\n",
    "    np.save('Normalizing_files/min_flat_x_156', min_xyz[0])\n",
    "    np.save('Normalizing_files/max_flat_x_156', max_xyz[0])\n",
    "\n",
    "    np.save('Normalizing_files/min_flat_y_156', min_xyz[1])\n",
    "    np.save('Normalizing_files/max_flat_y_156', max_xyz[1])\n",
    "\n",
    "    np.save('Normalizing_files/min_flat_z_156', min_xyz[2])\n",
    "    np.save('Normalizing_files/max_flat_z_156', max_xyz[2])\n",
    "\n",
    "#save_min_max_xyz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_flat = np.load('Normalizing_files/min_flat_3d.npy')\n",
    "max_flat = np.load('Normalizing_files/max_flat_3d.npy')\n",
    "\n",
    "min_flat_x = np.load('Normalizing_files/min_flat_x_156.npy')\n",
    "max_flat_x = np.load('Normalizing_files/max_flat_x_156.npy')\n",
    "\n",
    "min_flat_y = np.load('Normalizing_files/min_flat_y_156.npy')\n",
    "max_flat_y = np.load('Normalizing_files/max_flat_y_156.npy')\n",
    "\n",
    "min_flat_z = np.load('Normalizing_files/min_flat_z_156.npy')\n",
    "max_flat_z = np.load('Normalizing_files/max_flat_z_156.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>ind</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>002_S_0295_S110476-T1_T1_brain_mni305.nii</td>\n",
       "      <td>002_S_0295_110476</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>002_S_0295_S13408_T1_brain_mni305.nii</td>\n",
       "      <td>002_S_0295_13408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>002_S_0295_S150055-T1_T1_brain_mni305.nii</td>\n",
       "      <td>002_S_0295_150055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>002_S_0295_S21856_T1_brain_mni305.nii</td>\n",
       "      <td>002_S_0295_21856</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>002_S_0295_S32678_T1_brain_mni305.nii</td>\n",
       "      <td>002_S_0295_32678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10430</td>\n",
       "      <td>941_S_6570_S723995_T1_brain_mni305.nii</td>\n",
       "      <td>941_S_6570_723995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10431</td>\n",
       "      <td>941_S_6574_S725814_T1_brain_mni305.nii</td>\n",
       "      <td>941_S_6574_725814</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10432</td>\n",
       "      <td>941_S_6575_S725107_T1_brain_mni305.nii</td>\n",
       "      <td>941_S_6575_725107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10433</td>\n",
       "      <td>941_S_6580_S725681_T1_brain_mni305.nii</td>\n",
       "      <td>941_S_6580_725681</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10434</td>\n",
       "      <td>941_S_6581_S727038_T1_brain_mni305.nii</td>\n",
       "      <td>941_S_6581_727038</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9649 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        filename                ind label\n",
       "0      002_S_0295_S110476-T1_T1_brain_mni305.nii  002_S_0295_110476     0\n",
       "1          002_S_0295_S13408_T1_brain_mni305.nii   002_S_0295_13408     0\n",
       "2      002_S_0295_S150055-T1_T1_brain_mni305.nii  002_S_0295_150055     0\n",
       "3          002_S_0295_S21856_T1_brain_mni305.nii   002_S_0295_21856     0\n",
       "4          002_S_0295_S32678_T1_brain_mni305.nii   002_S_0295_32678     0\n",
       "...                                          ...                ...   ...\n",
       "10430     941_S_6570_S723995_T1_brain_mni305.nii  941_S_6570_723995     0\n",
       "10431     941_S_6574_S725814_T1_brain_mni305.nii  941_S_6574_725814     0\n",
       "10432     941_S_6575_S725107_T1_brain_mni305.nii  941_S_6575_725107     0\n",
       "10433     941_S_6580_S725681_T1_brain_mni305.nii  941_S_6580_725681     0\n",
       "10434     941_S_6581_S727038_T1_brain_mni305.nii  941_S_6581_727038     0\n",
       "\n",
       "[9649 rows x 3 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names_=pd.DataFrame()\n",
    "for filename in file_names:\n",
    "    row=dict()\n",
    "    row['filename']=filename[5:]\n",
    "    filename=filename[5:]\n",
    "    try:\n",
    "        series_id = re.search(pattern1, filename).group(0)[1:]\n",
    "        subject = re.search(pattern2,filename).group(0)\n",
    "        ind=subject+\"_\"+series_id\n",
    "        row['ind']=ind\n",
    "        row['label']=labels.loc[ind,'Group'] \n",
    "    except:\n",
    "        row['ind']= 'No label'\n",
    "        row['label']= 'No label'   \n",
    "    file_names_=file_names_.append(row,ignore_index=True)\n",
    "\n",
    "file_names = file_names_[file_names_['ind']!='No label']\n",
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle table:\n",
    "file_names = file_names.sample(frac=1, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = int(len(file_names)/10)\n",
    "\n",
    "testing_file_names = file_names[:cut]\n",
    "validation_file_names = file_names[cut:2*cut]\n",
    "training_file_names = file_names[2*cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 :  2424\n",
      "Class 1 :  1002\n",
      "Class 2 :  1423\n",
      "Class 3 :  705\n",
      "Class 4 :  2167\n",
      "Proportion: 2.42 : 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_count = training_file_names.label.value_counts().sort_index()\n",
    "df_classes = dict()\n",
    "for keys, values in target_count.items():\n",
    "    print('Class', keys, ': ', values)\n",
    "    df_classes[keys] = training_file_names[training_file_names['label'] == keys]\n",
    "\n",
    "print('Proportion:', round(target_count[0] / target_count[1], 2), ': 1')\n",
    "\n",
    "target_count.plot(kind='bar', title='Count (target)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class count\n",
    "count_class_0 = training_file_names.label.value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random over-sampling:\n",
      "4    2424\n",
      "3    2424\n",
      "2    2424\n",
      "1    2424\n",
      "0    2424\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_classes_over = dict()\n",
    "training_file_names_over = pd.DataFrame()\n",
    "for key in df_classes:\n",
    "    df_classes_over[key]= df_classes[key].sample(count_class_0, replace=True)\n",
    "    training_file_names_over = pd.concat([training_file_names_over, df_classes_over[key]], axis=0)\n",
    "#training_file_names_over = pd.concat([df_class_0, df_class_1_over, df_class_2_over, df_class_3_over, df_class_4_over], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(training_file_names_over.label.value_counts())\n",
    "training_file_names_over.label.value_counts().plot(kind='bar', title='Count (target)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>ind</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>041_S_4051_S194895_T1_brain_mni305.nii</td>\n",
       "      <td>041_S_4051_194895</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>136_S_0426_S14581_T1_brain_mni305.nii</td>\n",
       "      <td>136_S_0426_14581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>137_S_4631_S464254-T1_T1_brain_mni305.nii</td>\n",
       "      <td>137_S_4631_464254</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>020_S_1288_S145793_T1_brain_mni305.nii</td>\n",
       "      <td>020_S_1288_145793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>007_S_1304_S39694-T1_T1_brain_mni305.nii</td>\n",
       "      <td>007_S_1304_39694</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    filename                ind label\n",
       "0     041_S_4051_S194895_T1_brain_mni305.nii  041_S_4051_194895     2\n",
       "1      136_S_0426_S14581_T1_brain_mni305.nii   136_S_0426_14581     1\n",
       "2  137_S_4631_S464254-T1_T1_brain_mni305.nii  137_S_4631_464254     3\n",
       "3     020_S_1288_S145793_T1_brain_mni305.nii  020_S_1288_145793     0\n",
       "4   007_S_1304_S39694-T1_T1_brain_mni305.nii   007_S_1304_39694     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(12120, 3)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_file_names_over = training_file_names_over.sample(frac=1).reset_index(drop=True)\n",
    "display(training_file_names_over.head())\n",
    "training_file_names_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../data'):\n",
    "    os.makedirs('../data')\n",
    "\n",
    "training_file_names_over.to_csv('../data/training_file_names_over.csv')\n",
    "testing_file_names.to_csv('../data/testing_file_names.csv')\n",
    "validation_file_names.to_csv('../data/validation_file_names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tfrecords(save_filename, file_names, min_, max_ , dim=None, cut=None):\n",
    "    '''\n",
    "    raveling all three dimensions and normalizing every entry\n",
    "    '''\n",
    "    i=0\n",
    "    writer = tf.compat.v1.python_io.TFRecordWriter(save_filename)\n",
    "    for index, row in file_names.iterrows():\n",
    "        filename = row['filename']\n",
    "        label = int(row['label'])\n",
    "        name = str.encode(row['ind'])\n",
    "        try:\n",
    "            image_ = nib.load('data/'+filename)\n",
    "            im = image_.get_data()\n",
    "            if dim:\n",
    "                if dim==\"x\":\n",
    "                    im = crop_image[cut,:,:]\n",
    "                elif dim==\"y\":\n",
    "                    im = crop_image[:,cut,:]\n",
    "                elif dim==\"z\":\n",
    "                    im = crop_image[:,:,cut]\n",
    "            normalized_im = (im.ravel()-min_)/(max_+0.0001-min_)\n",
    "            feature = {'label': _int64_feature(label),\n",
    "                   'image': _float_feature(normalized_im),\n",
    "                     'name': _bytes_feature(name)}\n",
    "            # Create an example protocol buffer - Protocol buffers are a cross-platform, \n",
    "            #    cross-language library for efficient serialization of structured data.\n",
    "            example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "            # Serialize to string and write on the file\n",
    "            writer.write(example.SerializeToString())\n",
    "            i+=1\n",
    "            if i%500==0:\n",
    "                print('i: ',i)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tfrecords('../data/training_flat_256_3d.tfrecords', training_file_names_over, min_flat, max_flat)\n",
    "write_tfrecords('../data/testing_flat_256_3d.tfrecords', testing_file_names, min_flat, max_flat)\n",
    "write_tfrecords('../data/validation_flat_256_3d.tfrecords', validation_file_names, min_flat, max_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tfrecords('../data/training_flat_x_156_full_dataset.tfrecords',\n",
    "                training_file_names_over, min_flat_x, max_flat_x, \"x\", 127)\n",
    "write_tfrecords('../data/testing_flat_x_156_full_dataset.tfrecords',\n",
    "                testing_file_names, min_flat_x, max_flat_x, \"x\", 127)\n",
    "write_tfrecords('../data/validation_flat_x_156_full_dataset.tfrecords',\n",
    "                validation_file_names, min_flat_x, max_flat_x, \"x\", 127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "..data/testing_flat_y_156_full_dataset.tfrecords; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-f1541c328674>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                 training_file_names_over, min_flat_y, max_flat_y, \"y\", 127)\n\u001b[1;32m      3\u001b[0m write_tfrecords('..data/testing_flat_y_156_full_dataset.tfrecords',\n\u001b[0;32m----> 4\u001b[0;31m                 testing_file_names, min_flat_y, max_flat_y, \"y\", 127)\n\u001b[0m\u001b[1;32m      5\u001b[0m write_tfrecords('..data/validation_flat_y_156_full_dataset.tfrecords',\n\u001b[1;32m      6\u001b[0m                 validation_file_names, min_flat_y, max_flat_y, \"y\", 127)\n",
      "\u001b[0;32m<ipython-input-124-5368ab949512>\u001b[0m in \u001b[0;36mwrite_tfrecords\u001b[0;34m(save_filename, file_names, min_, max_, dim, cut)\u001b[0m\n\u001b[1;32m      4\u001b[0m     '''\n\u001b[1;32m      5\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/lib/io/tf_record.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, options)\u001b[0m\n\u001b[1;32m    216\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m       self._writer = pywrap_tensorflow.PyRecordWriter_New(\n\u001b[0;32m--> 218\u001b[0;31m           compat.as_bytes(path), options._as_record_writer_options(), status)\n\u001b[0m\u001b[1;32m    219\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    557\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: ..data/testing_flat_y_156_full_dataset.tfrecords; No such file or directory"
     ]
    }
   ],
   "source": [
    "write_tfrecords('../data/training_flat_y_156_full_dataset.tfrecords',\n",
    "                training_file_names_over, min_flat_y, max_flat_y, \"y\", 127)\n",
    "write_tfrecords('..data/testing_flat_y_156_full_dataset.tfrecords',\n",
    "                testing_file_names, min_flat_y, max_flat_y, \"y\", 127)\n",
    "write_tfrecords('..data/validation_flat_y_156_full_dataset.tfrecords',\n",
    "                validation_file_names, min_flat_y, max_flat_y, \"y\", 127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tfrecords('..data/training_flat_z_156_full_dataset.tfrecords',\n",
    "                training_file_names_over, min_flat_z, max_flat_z, \"z\", 127)\n",
    "write_tfrecords('..data/testing_flat_z_156_full_dataset.tfrecords',\n",
    "                testing_file_names, min_flat_z, max_flat_z, \"z\", 127)\n",
    "write_tfrecords('..data/validation_flat_z_156_full_dataset.tfrecords',\n",
    "                validation_file_names, min_flat_z, max_flat_z, \"z\", 127)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
